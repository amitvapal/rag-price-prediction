205_week8_day2_JustCode_test_RAG_pipeline.ipynb



## 1. **PIP Installations**

 
!pip install torch transformers accelerate huggingface_hub bitsandbytes anthropic

# Install RAPIDS libraries for GPU
!pip install cudf-cu12 --extra-index-url=https://pypi.nvidia.com
!pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com

# Install ChromaDB and Items
!pip install -q chromadb Items




## 2. **GPU and System Checks**
import torch

# Check CUDA version
!nvcc --version

print("="*70)
print("GPU VERIFICATION")
print("="*70)
print(f"CUDA Available: {torch.cuda.is_available()}")
assert torch.cuda.is_available(), "‚ùå CUDA GPU not found! Change runtime to GPU."

print(f"GPU Device: {torch.cuda.get_device_name(0)}")
print(f"Current Device: {torch.cuda.current_device()}")
print(f"Device Count: {torch.cuda.device_count()}")

gpu_name = torch.cuda.get_device_name(0)
if "L4" not in gpu_name:
    print(f"‚ö†Ô∏è Non-L4 GPU detected: {gpu_name}")
else:
    print(f"‚úì Using L4 GPU: {gpu_name}")
print("="*70)

# Set device
device = torch.device('cuda')





 ## 3. *Setup Claude API Client**

from google.colab import userdata
import anthropic

# Get API key from Colab secrets
api_key = userdata.get('ANTHROPIC_API_KEY')

# Create Claude client
claude_client = anthropic.Anthropic(api_key=api_key)

print("‚úì Claude API client initialized")




## 4. **Mount Google Drive**
from google.colab import drive

# Unmount if already mounted
drive.flush_and_unmount()

# Remount
drive.mount('/content/drive', force_remount=True)

# Navigate to your folder
os.chdir('/content/drive/MyDrive/01-LLM-ed-donner/build_multi_agent_system')

# Get current working directory
print(f"Current directory: {os.getcwd()}")

# List contents
print("\nContents:")
for item in os.listdir('.'):
    print(f"  üìÅ {item}" if os.path.isdir(item) else f"  üìÑ {item}")

# Full path example
file_path = os.path.join(os.getcwd(), '202_week8_day2_CUDA-code-chroma_vector_db_advanced_rag_pipeline.ipynb')
print(f"Full path: {file_path}")



## 5. **Main Imports**
# ===================================================================
# STEP 1: Standard library imports
# ===================================================================
import sys
import os
import re
import math
import json
import random
from datetime import datetime
import pickle
import time

# ===================================================================
# STEP 2: Third-party imports
# ===================================================================
from tqdm import tqdm
from dotenv import load_dotenv

import torch
from sentence_transformers import SentenceTransformer
 

import chromadb

from sklearn.manifold import TSNE
import numpy as np
import plotly.graph_objects as go

# ===================================================================
# STEP 3: Setup Python path BEFORE importing custom modules
# ===================================================================
base_path = '/content/drive/MyDrive/01-LLM-ed-donner/build_multi_agent_system'

# Change to base directory
os.chdir(base_path)

# Add scripts folder to Python path
scripts_path = os.path.join(base_path, 'scripts')
if scripts_path not in sys.path:
    sys.path.insert(0, scripts_path)

print("="*70)
print("PATH SETUP")
print("="*70)
print(f"Current directory: {os.getcwd()}")
print(f"Scripts path added: {scripts_path}")
print(f"Scripts folder exists: {os.path.exists(scripts_path)}")

# List files in scripts folder to verify
if os.path.exists(scripts_path):
    print("\nFiles in scripts folder:")
    for file in os.listdir(scripts_path):
        print(f"  - {file}")

print("="*70)

# ===================================================================
# STEP 4: NOW import custom modules (after path is configured)
# ===================================================================
try:
    from preprocess_data import Item
    print("‚úì Successfully imported Item from preprocess_data")
except ImportError as e:
    print(f"‚ùå Failed to import Item: {e}")
    # Try alternative import
    try:
        from items import Item
        print("‚úì Successfully imported Item from items")
    except ImportError as e2:
        print(f"‚ùå Failed to import from items too: {e2}")

try:
    from testing import Tester
    print("‚úì Successfully imported Tester from testing")
except ImportError as e:
    print(f"‚ùå Failed to import Tester: {e}")

print("\n‚úì All imports configured successfully")



 

## 6. **Copy Dataset to Colab VM**
print("="*70)
print("COPYING DATASET TO LOCAL VM")
print("="*70)

# Define paths
drive_data_folder = "/content/drive/MyDrive/01-LLM-ed-donner/build_multi_agent_system/data/final_v_02"
local_data_folder = "/content/final_data"

# Copy from Drive to local disk for faster access
print(f"Copying from Drive to {local_data_folder}...")
!cp -r "$drive_data_folder" "$local_data_folder"
print("‚úì Copy complete")

# Update data_folder variable
data_folder = local_data_folder

# Load pickle files
print("Loading pickle files...")
with open(os.path.join(data_folder, "train.pkl"), 'rb') as file:
    train = pickle.load(file)

with open(os.path.join(data_folder, "test.pkl"), 'rb') as file:
    test = pickle.load(file)

print(f"‚úì Loaded train: {len(train):,} items")
print(f"‚úì Loaded test: {len(test):,} items")
print("="*70)


## 7. **Copy Vector Database to Colab VM**
print("="*70)
print("COPYING VECTOR DATABASE TO LOCAL VM")
print("="*70)

# Define paths
drive_db_source = "/content/drive/MyDrive/01-LLM-ed-donner/build_multi_agent_system/products_vectorstore"
local_db_path = "/content/products_vectorstore"

# Copy database
print("Copying database from Drive to local disk...")
!cp -r "$drive_db_source" /content/
print("‚úì Copy complete")

# Create ChromaDB client
client = chromadb.PersistentClient(path=local_db_path)
collection = client.get_or_create_collection('products')

print(f"‚úì ChromaDB connected")
print(f"‚úì Collection count: {collection.count():,} items")
print("="*70)



## 8. **Load Sentence Transformer Model**
print("="*70)
print("LOADING SENTENCE TRANSFORMER ON GPU")
print("="*70)

# Force GPU usage
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Loading Sentence Transformer on {device}...")

model_sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2', device=device)

print(f"‚úì Sentence Transformer on: {model_sentence_transformer.device}")
print("="*70)


## 11. **Helper Functions**
## 11. **Helper Functions**

def description(item):
    """Extract clean product description from item"""
    text = item.prompt.replace("How much does this cost to the nearest dollar?\n\n", "")
    return text.split('\n\nPrice is $')[0]


def vector(item):
    """Generate embedding vector for item using Sentence Transformer (GPU optimized)"""
    with torch.no_grad():
        embedding = model_sentence_transformer.encode(
            [description(item)],
            convert_to_tensor=True,
            device='cuda'
        )
    return embedding.cpu().numpy()  # Convert to numpy for ChromaDB


def find_similars(item, n_results=5):
    """Find similar items from ChromaDB vector store"""
    results = collection.query(
        query_embeddings=vector(item).astype(float).tolist(),
        n_results=n_results
    )
    documents = results['documents'][0][:]
    prices = [m['price'] for m in results['metadatas'][0][:]]
    return documents, prices


def make_context(similars, prices):
    """Format similar items into context string for LLM"""
    message = "To provide some context, here are some other items that might be similar to the item you need to estimate.\n\n"
    for similar, price in zip(similars, prices):
        message += f"Potentially related product:\n{similar}\nPrice is ${price:.2f}\n\n"
    return message


def get_price(s):
    """Extract numeric price from string"""
    s = s.replace('$', '').replace(',', '')
    match = re.search(r"[-+]?\d*\.?\d+", s)
    return float(match.group()) if match else 0


print("‚úì All helper functions defined")





## 12. **Claude RAG Prediction Function**

def claude_rag(item):
    """
    Use Claude with RAG to predict item price
    """
    # Get similar items from vector DB
    documents, prices = find_similars(item)
    
    # Build multi-shot prompt with similar items as examples
    user_message = "You are a price estimation expert. Based on similar products, estimate the price of the given item.\n\n"
    user_message += "Here are some similar products with their prices:\n\n"
    
    # Add each similar item as context
    for i, (doc, price) in enumerate(zip(documents, prices), 1):
        user_message += f"Example {i}:\n{doc}\nPrice: ${price:.2f}\n\n"
    
    user_message += f"Now estimate the price for this item:\n{description(item)}\n\n"
    user_message += "Respond with ONLY the numeric price value (no dollar sign or other text)."
    
    # Call Claude API
    message = claude_client.messages.create(
        model="claude-sonnet-4-5-20250929",
        max_tokens=100,
        messages=[
            {"role": "user", "content": user_message}
        ]
    )
    
    # Extract and parse response
    reply = message.content[0].text.strip()
    
    return get_price(reply)

print("‚úì Claude RAG function defined")







## 12. **Test RAG Pipeline**
print("="*70)
## 13. **Test Claude RAG Pipeline**

print("="*70)
print("TESTING CLAUDE RAG PIPELINE")
print("="*70)

start_time = time.time()
Tester.test(claude_rag, test)
end_time = time.time()

total_time = end_time - start_time
print(f"\n‚è±Ô∏è Processing time: {total_time:.2f} seconds")
print(f"‚è±Ô∏è Time per item: {total_time / len(test):.2f} seconds")
print("="*70)

